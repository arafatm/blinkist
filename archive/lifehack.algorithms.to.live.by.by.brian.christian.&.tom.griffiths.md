# Algorithms to Live By

![Algorithms to Live
By](https://images.blinkist.com/images/books/5829dd0f92e9210004940bf6/3_4/470.jpg)

## The key message in this book:

Algorithms are not incomprehensible things that only exist to help
mathematicians and computers. In fact, we use them every day, even if we’re
unaware of it. Algorithms contain a lot of problem-solving wisdom that can help
you make good decisions, predict probable outcomes and become a more productive
individual.

## Actionable advice:

**Do the simple stuff first.**

The next time your to-do list gets too long and you want to check off as many
things as possible, go for the **Shortest Processing Time algorithm** 

List your tasks in order of what can be done the fastest. This enables you to
get lots of things done in a very short period of time.

## What’s in it for me? Put algorithms to use in your own life.

Let’s take a second to think about that smartphone or tablet in front of you.
How does it “think”? For instance, how does it “know” how to handle a heap of
data and present it to you as the blinks you’re reading – or listening to –
right now? The answer, of course, is that a series of instructions – or, in
other words, an algorithm – enables it to do this.

But, as you’ll learn from these blinks, it’s not only computers that use
algorithms. They also play a part in your own thinking, in your gut feelings
and decisions. And here’s the best part: when your own algorithms aren’t up to
the task of solving a difficult problem in your life, you can turn to simple
but powerful computer algorithms for help.

In these blinks, you’ll learn
- how math can tell you when to stop dating and settle for the partner you’re
  with;
- how algorithms can help you sort your collection of zombie books; and
- why that mess on your desk isn’t half as bad as it looks.

## Algorithms help both humans and computers to solve problems.

If you’re someone who tries to stay abreast of today’s
technology, you probably already know that computers use
**algorithms** all the time to solve problems. But you may have
asked yourself, “What exactly is an algorithm?”

The word actually dates back to the ninth century, when it was
first used by the Persian mathematician Muhammad al-Khwarizmi.
But the use of algorithms can be traced roughly four thousand
years back, to the Sumerian civilization.

Simply put, an algorithm is a finite series of steps that help
solve a problem – and it’s a technique we use all the time.

Even a recipe can be thought of as an algorithm: you follow a
series of instructions to get the desired result, a delicious
meal. The same can be said for the pattern you follow to knit a
scarf or put together some Ikea furniture.

And when you’re putting together a list of pros and cons to
decide whether or not to accept a job offer or to make a big
decision, you’re also following what’s known as an **intuitive
algorithm**.

By their very nature, the intuitive algorithms that humans use
aren’t precise. We use them in times of uncertainty to make the
best decision we can, like weighing the potential benefits
against the risks of jumping into a new business investment.

Therefore, these intuitive algorithms may seem rather
subjective and random compared to the mathematical algorithms a
computer uses, though they basically provide the same solution.

Take the unpleasant task of apartment hunting. Most people go
into this process with a set of criteria in mind: a minimum
amount of space, a certain distance from school or work, a
maximum amount of rent. When these conditions are met, that’s
when you take the next step and sign the lease.

This is essentially the same method that computer algorithms
use, and in the next blinks we’ll explore how these methods can
work for you.

## Most of the time, algorithms can tell us when to stop pressing our luck.

If you’ve been out searching for an apartment in a competitive
market, you probably know how difficult it can be to decide
when to take an offer and stop searching.

Our judgment is often clouded by the first thing that comes
along, which we tend to perceive as the best option available.
And, just as easily, the second option can seem like the next
best thing.

These problems are exactly what the **optimal stopping**
algorithm is designed to help solve.

Mathematically speaking, if there are 100 options, optimal
stopping says to look at the first 37 without taking any of
them. Instead, look at them to establish a standard, such as
excluding apartments that are on the ground floor and have
small bathrooms.

Then, after the first 37, you should jump on the first one that
meets these standards. While this strategy doesn’t guarantee
that you’ll end up with the best, these optimal odds are far
better than just making a guess.

And it doesn’t just apply to apartments; whether you’re looking
for a car, a job or a potential mate, the magic number is
always 37 percent.

Unfortunately, math doesn’t always tell us the right time to
stop.

Let’s look at a simple coin flip. Say you want to bet on the
outcome using the “triple or nothing” strategy, meaning you
triple the bet with each flip but also risk losing everything
you’ve won so far.

So, if you start with four dollars, and your odds are 50/50,
half the time you’ll end up with nothing and the other half
with twelve dollars, so, on average, you’d expect to have six
dollars in your pocket. In the next round, with a twelve-dollar
starting bet, the odds stay the same, but you can expect to end
up with eighteen dollars, and so on.

With these odds and averages, pure mathematics would suggest
that you keep on betting due to the increasing amount of money
you can expect to win. But of course, sooner or later you’d
lose everything and the game would be over. So, a purely
mathematical algorithm doesn’t work in **every** situation.

## Mathematical algorithms can help you decide when it’s time to explore something new.

Let’s stick with gambling for a minute and look at one of the
most popular games at any casino: the slot machine, or
“one-armed bandit.”

While some people are happy to sit at a single slot machine all
day in the hopes of eventually hitting the jackpot, others
prefer to explore their options, gather information and try to
use it to their advantage. This same basic dilemma of how long
to stick with a losing option before moving on applies to a
number of situations in life, such as dating or investing. But
what’s the winning strategy?

In math, questions like this are called **multi-armed bandit
problems**, and they have several different answers.

The easiest approach to improving your odds at the slot
machines is called “stay-win, lose-shift” – but it may not be
the best strategy.

All you have to do is stick with one machine as long as you’re
winning and shift to another one once you lose. But this
approach can be misleading since a one-time loss isn’t the best
indicator of how your luck will turn out.

A better method is the **Upper Confidence Bound** algorithm.

Here’s how you use it: First, find the machine that offers the
best **expected value** for playing. In this case, the only
information you have is the jackpot counter, so you pick the
one with the biggest jackpot. As you’re playing, keep track of
the real outcome – in this case, how much money you’re winning
– and note whether it’s gradually getting better or gradually
getting worse than you’d expect. If the real outcome is
continually disappointing you, that’s when you move to the next
machine with the second biggest jackpot. And so on.

Since this algorithm takes into account the fact that a good
machine can still provide an occasional loss, it increases your
chances of winning.

Another source of inspiration for solving multi-armed bandit
problems comes from **adaptive clinical trials** in the
pharmaceutical industry. When doctors are testing different
drugs for an ailment, they continuously evaluate their subjects
and make on-the-fly changes to their testing plan, even before
the trial is over. If a drug doesn’t seem to be working, they
will immediately put a stop to it and focus on other drugs that
were helpful. They are always ready to exploit new information
before the final results are even in.

## You don’t always need help sorting your files, but if you do, algorithms can help.

Do you ever feel like you can’t find anything you’re looking
for once your desk or office gets cleaned up? Well, if you’re
the kind of person who prefers a certain amount of organized
chaos, then you’ll be happy to hear this next bit of advice.

Don’t worry about always keeping everything neat and tidy.

After all, the main reason to have everything sorted and in
order is to make it easy to find something when you need it.
And sorting through your stacks of paper can take a lot of time
and energy that could be better spent doing other things,
especially if you already know exactly where everything is!

But let’s say your messy filing system is making you look like
a hoarder and you want a better way to sort things out. Luckily
for you, there are algorithms just for this.

Let’s start with the least efficient method, the **bubble
sort**. This works by organizing one pair of things at a time,
over and over again, until everything is sorted out.

Say you want to alphabetize your massive collection of books
about zombies: First, you go to the area of your disorganized
shelves where books beginning with A belong, look at the first
two items that are already there and put those two in order.
Now you might have “Albatross Zombies” followed by “Alligator
Zombies.”

Now move to the next book – “Aardvark Zombies” – and sort it
against the last item from the previous pair, “Alligator
Zombies.” Now, your shelf should consist of: “Albatross
Zombies” followed by “Aardvark Zombies” followed by “Alligator
Zombies.” Then you repeat this until you’ve gone through all
your books and start over however many times it takes until
your entire collection is sorted, meaning you no longer need to
switch the places of any books.

Obviously, if you have a house full of books, this isn’t the
easiest way to do things. A better way to go is to use the**
insertion sort**: Take all your books off the shelf and simply
put them back, one by one, always ensuring each one goes in the
right place compared to the books you’ve already put back.

Even better for massive collections is the **merge sort**
method: divide everything into multiple piles, sort those from
A to Z and then merge the piles together afterward.

## When it comes to organizing data, there’s a lot you can learn from computers.

Now that your shelves are in order, let’s turn to those stacks
of paper on your desk and all the notes and info that you keep
close at hand. These are probably important things, like
pending bills or letters needing an urgent reply – documents
requiring easy access.

Computers have a pretty useful way of dealing with things that
need to be quickly retrieved. They store their data either in a
**hard disk drive** or a **solid state drive**. Each comes with
its own advantages.

While hard drives can store more data, solid-state drives
(SSDs) are quicker at getting that data to you. Nowadays, many
devices combine these drives, storing important things in a
fast SSD and using a hard drive to store big archives.

But the most important and most frequently used information is
stored in the **cache**, the treasured upper layer of memory
that can be accessed quickest of all.

Computers use a simple algorithm to decide what gets stored in
the cache. It’s called Last Recently Used (LRU), and it
basically stores whatever you used last on top, in the upper
layer of the cache.

This algorithm is a simple way for your computer to guess which
file might be needed in the future. Luckily, it also works well
in the analog world for bills, important letters and things you
need to keep in reach and on your mind.

This means that all the clutter on your desk can stay where it
is, because, probably, your organized mess already has all your
recently used items and most important letters sitting right on
top!

Our brains work in a similar fashion as well: if some
information goes unused for a long time, we have a hard time
remembering it.

So, if you’re preparing for a big exam or meeting in the
morning, read your notes right before you go to bed. The
information will be more easily accessible when you wake up.

## Algorithms can help us schedule our lives, but they also have their limits.

Aside from getting files in order, another key to productivity
is organizing your time and figuring out how to get everything
done. Every day has its challenges. It can be difficult to find
the time to meet all your deadlines – and not forget to take
the dog to the vet.

Fortunately, there are plenty of algorithms that deal with
these kinds of scheduling problems.

For instance, if you’re juggling multiple tasks and not sure
where to begin, use the **Earliest Due Date **algorithm and
always start with the task that has the closest deadline.

If time is running out and you know that you’re not going to
get everything done, follow **Moore’s Algorithm** and skip the
task that requires the most time; this way, you’ll get more
tasks done overall.

But whatever you do, beware of **priority inversion**. This
happens when minor tasks take up all your time and energy and
nothing important gets done.

Unfortunately, there are no time-management silver bullets.
Studies have shown that the majority of the scheduling problems
we face can’t be solved with a quick-and-easy solution.

And of course, scheduling itself can eat up a lot of your day,
so be sure to limit the amount of time you devote to organizing
your time.

This probably sounds pretty complicated, but when in doubt,
there’s one simple method you can use to get the most done in
the shortest amount of time:

Focus on one thing at a time and ignore any emails or other
requests you receive while doing so. Constantly switching your
attention from the task to your inbox and back is incredibly
time-consuming and overwhelming, because every switch burdens
your working memory and requires you to start afresh. So just
focus on one task at a time, and ignore any and all
distractions. Don’t even worry about the length of your to-do
list; it will all get done in due time.

With this in mind, you should be able to accomplish more and
increase your productivity without even worrying about where to
start.

## The right algorithms can help you predict the future.

Most of us would love to be able to see into the future, but
what about the next best thing: predicting what will probably
happen?

With the help of algorithms, predicting probable outcomes isn’t
so far-fetched.

This kind of forecasting goes back to eighteenth-century
England, when Reverend Thomas Bayes figured out a basic method
for predicting the likelihood of future events, such as drawing
a winning lottery ticket, given certain prior events.

Let’s try applying Bayes’s logic to today’s lottery scratch
tickets. Imagine you bought three scratchers and want to use
them to understand what proportion of the tickets in
circulation offer some kind of win. Bayes’s insight was that
you have to start by hypothesizing about the prevalence of
winners among all the tickets in circulation, and using this as
an assumption, calculate the probability of the results you
actually see in your three tickets.

For example, if all three of your tickets are winners, you
could reasonably assume that all tickets in circulation offer a
win. After all, if all tickets are winners, then you should
witness three out of three tickets winning 100 percent of the
time. But if only half the tickets were winners, then your
threefold luck would have only had a 12.5-percent chance of
befalling you. So it’s far likelier that all the tickets are
winners.

Of course, the more information you collect, the more precise
your next hypothesis will be.

But, over the years, math has developed and given us more
precise tools to make better predictions.

What significantly helps those predictions is to understand the
**distribution pattern** of a phenomenon.

For instance, there’s the famous “bell curve,” modeled on a
**normal distribution**, which applies to many phenomena. When
predicting the average age of a random group of people, you can
assume that few people are extremely young or extremely old;
most fall somewhere in the middle of the bell. This way, if
you’re going on a blind date, you can be reasonably sure you
won’t be dining with a nonagenarian.

Other situations follow the **power-law-distribution**, which
is quite different.

In these cases, we reach the median average by having most
observations falling below it and only a few enormous ones
falling above it. An excellent example of this is wealth
distribution. Generally speaking, there are many poor people
and only a select few that own the lion’s share of the world’s
wealth.

## Algorithms help us to exchange messages and handle data overload.

Here’s a classic thought experiment: Two generals are preparing
to launch a joint attack on a city located in a fortified
valley. The only problem is that each general is on a hill with
the valley separating them, and before they can attack they
need to agree on the exact time. However, the only way to get a
message across is to send someone through the valley, where
their messengers are likely to be captured. So how can they
determine a time and know that the other has agreed to it?

This kind of problem is something computer scientists pondered
in order to come up with algorithms to help ensure messages get
to their destination safely.

The first method they devised is called **retransmitted till
breakdown**. The idea would be to send in messenger after
messenger, hoping that one will eventually make it through
without being captured.

This is essentially what we do when we keep texting or calling
a friend until they finally reply.

But of course, these days we mostly face other problems than
intercepted messengers. Let’s say that every time you’re going
to check your email you’re getting an error saying the server
is overloaded.

In this case, the **Exponential Backoff** method can help.
Instead of frantically hitting refresh, wait a couple minutes
for the traffic to ease up. And if you’re still getting the
error after that, double the waiting time to four minutes
before trying again, and keep doubling until it gets through.

Ideally, everyone trying to use the server would follow this
method, as it would help ensure a quick resolution.

But the best solution would be to prevent the overload problem
in the first place, a method called **Additive Increase,
Multiplicative Decrease** (AIMD).

This algorithm helps you determine the maximum amount of data a
network can handle. It starts by sending just one package of
data; then it sends double the amount each subsequent time
until it reaches the point of overload.

Then it tries to pinpoint the limit by sending the highest
amount before the failure occurred and increasing the
subsequent packages by a tiny amount until the limit is
reached.

## There are algorithms to help figure out what people will do and guide them when making decisions.

Have you ever heard of the **prisoner’s dilemma**? Imagine you
and a partner have successfully robbed a bank. Later, you’re
both brought in for questioning by the police and placed in
separate rooms. You know they don’t have sufficient evidence to
convict either of you for the robbery, so if you keep your
mouth shut, all they can do is give you a one-year sentence for
a lesser charge. After that, you will get out and can enjoy
your loot.

But here’s the twist: the cops offer both you and your partner
a deal: If you testify against your partner and he stays
silent, you’ll go free and he’ll go to jail for ten years.
However, if you both turn on each other, you’ll each get a
five-year sentence. What do you do?

This is a classic** s**trategic question that represents **game
theory**, which explores how rational people would respond to
such a situation.

In the case of the prisoners, they would almost certainly turn
on one another, in which case they’d each get a sentence of
five years.

In this scenario there is a clear **maximum reward** –
incriminate the other person, face no jail time and have a
chance of keeping all the money. Even if your partner also
talks, a five-year sentence is still better than the ten years
you would get if you stay silent.

But, in the end, since each person would end up testifying
against the other one, it’s the cops who win.

Another branch of game theory is the more straightforward
**mechanism design**. Rather than setting options in the hopes
of getting a certain reaction, it forces people to behave in a
desirable way.

For example, many employers face the problem of employees not
using their vacation time. And employers know that well-rested
employees perform much better than overworked ones. The company
Evernote went so far as to offer its staff a thousand-dollar
bonus for taking time off, but even this didn’t work.

When you apply mechanism design to this problem, you don’t need
to figure out ways of **convincing** your employees. All you
need to do is ask yourself how to **make **them take their
vacation.

And the answer is simple: Make vacations mandatory!

As you can see, algorithms have applications in many fields.
Finally, in the last blink, let’s discuss their limitations.

## It’s important to know that algorithms have their limits.

When you’re trying to model something complicated, complex
models are generally better than simple ones.

For example, if you’re developing a model to explain the cause
of obesity, you’ll want a complex one that takes many factors
into account, from a poor diet to genetics to lack of exercise.
A simple model might focus solely on diet, which would be
insufficient.

However, problems also arise when models grow too complex. This
is a risk when considering real-world problems, where there’s
always going to be uncertainty and errors in the data. Most
likely, you’d start with a sample data set and would try to
build an algorithm that makes predictions based on it. The
temptation is to add variables to the algorithm until it
explains everything in data perfectly, including the errors.
This is known as **overfitting,** and it creates problems when
you try to apply the same algorithm to different data.
Basically, the model has been so rigorously adapted to the
sample data that it has lost all flexibility and will not work
well with any other data.

For example, when considering obesity, in your sample data you
might notice that certain areas of the country have more
obesity than others. But this could well be a coincidence, and
if you tweak your model to emphasize the importance of a
person’s location, it will worsen the predictive power of the
model when you apply it to new data where location is
inconsequential.

When you realize that perfect algorithms don’t exist, you can
relax your standards a bit and go for good enough instead of
perfect.

Consider the **travelling-salesman-problem**, which asks: How
can you find the single best route between multiple points
without having to go anywhere twice. If you expand this problem
to a whole state or country, it gets unspeakably complex.

In a situation like this, the most efficient solution is to
relax your standards. Let your salesman visit different
locations at least twice. You’ll end up close to a good
solution in a reasonable time, even if it might not be a
perfect one.

As you’ve learned from these blinks, if you understand their
limits and possibilities, algorithms can be applied in many
areas of life.

## Suggested further reading: How Not to Be Wrong by Jordan Ellenberg

**How Not to Be Wrong** gives us an intimate glimpse into how mathematicians
think and how we can benefit from their way of thinking. It also explains how
easily we can be mistaken when we apply mathematical tools incorrectly, and
gives advice on how we can instead find correct solutions.
