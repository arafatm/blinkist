![Algorithms to Live By](https://images.blinkist.com/images/books/5829dd0f92e9210004940bf6/3_4/470.jpg)

# Algorithms to Live By

## What’s in it for me? Put algorithms to use in your own life.

Let’s take a second to think about that smartphone or tablet in front of you. How does it “think”? For instance, how does it “know” how to handle a heap of data and present it to you as the blinks you’re reading – or listening to – right now? The answer, of course, is that a series of instructions – or, in other words, an algorithm – enables it to do this.

But, as you’ll learn from these blinks, it’s not only computers that use algorithms. They also play a part in your own thinking, in your gut feelings and decisions. And here’s the best part: when your own algorithms aren’t up to the task of solving a difficult problem in your life, you can turn to simple but powerful computer algorithms for help.

In these blinks, you’ll learn

- how math can tell you when to stop dating and settle for the partner you’re with;
- how algorithms can help you sort your collection of zombie books; and
- why that mess on your desk isn’t half as bad as it looks.

## Algorithms help both humans and computers to solve problems.

If you’re someone who tries to stay abreast of today’s technology, you probably already know that computers use **algorithms** all the time to solve problems. But you may have asked yourself, “What exactly is an algorithm?”

The word actually dates back to the ninth century, when it was first used by the Persian mathematician Muhammad al-Khwarizmi. But the use of algorithms can be traced roughly four thousand years back, to the Sumerian civilization.

Simply put, an algorithm is a finite series of steps that help solve a problem – and it’s a technique we use all the time.

Even a recipe can be thought of as an algorithm: you follow a series of instructions to get the desired result, a delicious meal. The same can be said for the pattern you follow to knit a scarf or put together some Ikea furniture.

And when you’re putting together a list of pros and cons to decide whether or not to accept a job offer or to make a big decision, you’re also following what’s known as an **intuitive algorithm**.

By their very nature, the intuitive algorithms that humans use aren’t precise. We use them in times of uncertainty to make the best decision we can, like weighing the potential benefits against the risks of jumping into a new business investment.

Therefore, these intuitive algorithms may seem rather subjective and random compared to the mathematical algorithms a computer uses, though they basically provide the same solution.

Take the unpleasant task of apartment hunting. Most people go into this process with a set of criteria in mind: a minimum amount of space, a certain distance from school or work, a maximum amount of rent. When these conditions are met, that’s when you take the next step and sign the lease.

This is essentially the same method that computer algorithms use, and in the next blinks we’ll explore how these methods can work for you.

## Most of the time, algorithms can tell us when to stop pressing our luck.

If you’ve been out searching for an apartment in a competitive market, you probably know how difficult it can be to decide when to take an offer and stop searching.

Our judgment is often clouded by the first thing that comes along, which we tend to perceive as the best option available. And, just as easily, the second option can seem like the next best thing.

These problems are exactly what the **optimal stopping** algorithm is designed to help solve.

Mathematically speaking, if there are 100 options, optimal stopping says to look at the first 37 without taking any of them. Instead, look at them to establish a standard, such as excluding apartments that are on the ground floor and have small bathrooms.

Then, after the first 37, you should jump on the first one that meets these standards. While this strategy doesn’t guarantee that you’ll end up with the best, these optimal odds are far better than just making a guess.

And it doesn’t just apply to apartments; whether you’re looking for a car, a job or a potential mate, the magic number is always 37 percent.

Unfortunately, math doesn’t always tell us the right time to stop.

Let’s look at a simple coin flip. Say you want to bet on the outcome using the “triple or nothing” strategy, meaning you triple the bet with each flip but also risk losing everything you’ve won so far.

So, if you start with four dollars, and your odds are 50/50, half the time you’ll end up with nothing and the other half with twelve dollars, so, on average, you’d expect to have six dollars in your pocket. In the next round, with a twelve-dollar starting bet, the odds stay the same, but you can expect to end up with eighteen dollars, and so on.

With these odds and averages, pure mathematics would suggest that you keep on betting due to the increasing amount of money you can expect to win. But of course, sooner or later you’d lose everything and the game would be over. So, a purely mathematical algorithm doesn’t work in **every** situation.

## Mathematical algorithms can help you decide when it’s time to explore something new.

Let’s stick with gambling for a minute and look at one of the most popular games at any casino: the slot machine, or “one-armed bandit.”

While some people are happy to sit at a single slot machine all day in the hopes of eventually hitting the jackpot, others prefer to explore their options, gather information and try to use it to their advantage. This same basic dilemma of how long to stick with a losing option before moving on applies to a number of situations in life, such as dating or investing. But what’s the winning strategy?

In math, questions like this are called **multi-armed bandit problems**, and they have several different answers.

The easiest approach to improving your odds at the slot machines is called “stay-win, lose-shift” – but it may not be the best strategy.

All you have to do is stick with one machine as long as you’re winning and shift to another one once you lose. But this approach can be misleading since a one-time loss isn’t the best indicator of how your luck will turn out.

A better method is the **Upper Confidence Bound** algorithm.

Here’s how you use it: First, find the machine that offers the best **expected value** for playing. In this case, the only information you have is the jackpot counter, so you pick the one with the biggest jackpot. As you’re playing, keep track of the real outcome – in this case, how much money you’re winning – and note whether it’s gradually getting better or gradually getting worse than you’d expect. If the real outcome is continually disappointing you, that’s when you move to the next machine with the second biggest jackpot. And so on.

Since this algorithm takes into account the fact that a good machine can still provide an occasional loss, it increases your chances of winning.

Another source of inspiration for solving multi-armed bandit problems comes from **adaptive clinical trials** in the pharmaceutical industry. When doctors are testing different drugs for an ailment, they continuously evaluate their subjects and make on-the-fly changes to their testing plan, even before the trial is over. If a drug doesn’t seem to be working, they will immediately put a stop to it and focus on other drugs that were helpful. They are always ready to exploit new information before the final results are even in.

## You don’t always need help sorting your files, but if you do, algorithms can help.

Do you ever feel like you can’t find anything you’re looking for once your desk or office gets cleaned up? Well, if you’re the kind of person who prefers a certain amount of organized chaos, then you’ll be happy to hear this next bit of advice.

Don’t worry about always keeping everything neat and tidy.

After all, the main reason to have everything sorted and in order is to make it easy to find something when you need it. And sorting through your stacks of paper can take a lot of time and energy that could be better spent doing other things, especially if you already know exactly where everything is!

But let’s say your messy filing system is making you look like a hoarder and you want a better way to sort things out. Luckily for you, there are algorithms just for this.

Let’s start with the least efficient method, the **bubble sort**. This works by organizing one pair of things at a time, over and over again, until everything is sorted out.

Say you want to alphabetize your massive collection of books about zombies: First, you go to the area of your disorganized shelves where books beginning with A belong, look at the first two items that are already there and put those two in order. Now you might have “Albatross Zombies” followed by “Alligator Zombies.”

Now move to the next book – “Aardvark Zombies” – and sort it against the last item from the previous pair, “Alligator Zombies.” Now, your shelf should consist of: “Albatross Zombies” followed by “Aardvark Zombies” followed by “Alligator Zombies.” Then you repeat this until you’ve gone through all your books and start over however many times it takes until your entire collection is sorted, meaning you no longer need to switch the places of any books.

Obviously, if you have a house full of books, this isn’t the easiest way to do things. A better way to go is to use the** insertion sort**: Take all your books off the shelf and simply put them back, one by one, always ensuring each one goes in the right place compared to the books you’ve already put back.

Even better for massive collections is the **merge sort** method: divide everything into multiple piles, sort those from A to Z and then merge the piles together afterward.

## When it comes to organizing data, there’s a lot you can learn from computers.

Now that your shelves are in order, let’s turn to those stacks of paper on your desk and all the notes and info that you keep close at hand. These are probably important things, like pending bills or letters needing an urgent reply – documents requiring easy access.

Computers have a pretty useful way of dealing with things that need to be quickly retrieved. They store their data either in a **hard disk drive** or a **solid state drive**. Each comes with its own advantages.

While hard drives can store more data, solid-state drives (SSDs) are quicker at getting that data to you. Nowadays, many devices combine these drives, storing important things in a fast SSD and using a hard drive to store big archives.

But the most important and most frequently used information is stored in the **cache**, the treasured upper layer of memory that can be accessed quickest of all.

Computers use a simple algorithm to decide what gets stored in the cache. It’s called Last Recently Used (LRU), and it basically stores whatever you used last on top, in the upper layer of the cache.

This algorithm is a simple way for your computer to guess which file might be needed in the future. Luckily, it also works well in the analog world for bills, important letters and things you need to keep in reach and on your mind.

This means that all the clutter on your desk can stay where it is, because, probably, your organized mess already has all your recently used items and most important letters sitting right on top!

Our brains work in a similar fashion as well: if some information goes unused for a long time, we have a hard time remembering it.

So, if you’re preparing for a big exam or meeting in the morning, read your notes right before you go to bed. The information will be more easily accessible when you wake up.

## Algorithms can help us schedule our lives, but they also have their limits.

Aside from getting files in order, another key to productivity is organizing your time and figuring out how to get everything done. Every day has its challenges. It can be difficult to find the time to meet all your deadlines – and not forget to take the dog to the vet.

Fortunately, there are plenty of algorithms that deal with these kinds of scheduling problems.

For instance, if you’re juggling multiple tasks and not sure where to begin, use the **Earliest Due Date **algorithm and always start with the task that has the closest deadline.

If time is running out and you know that you’re not going to get everything done, follow **Moore’s Algorithm** and skip the task that requires the most time; this way, you’ll get more tasks done overall.

But whatever you do, beware of **priority inversion**. This happens when minor tasks take up all your time and energy and nothing important gets done.

Unfortunately, there are no time-management silver bullets. Studies have shown that the majority of the scheduling problems we face can’t be solved with a quick-and-easy solution.

And of course, scheduling itself can eat up a lot of your day, so be sure to limit the amount of time you devote to organizing your time.

This probably sounds pretty complicated, but when in doubt, there’s one simple method you can use to get the most done in the shortest amount of time:

Focus on one thing at a time and ignore any emails or other requests you receive while doing so. Constantly switching your attention from the task to your inbox and back is incredibly time-consuming and overwhelming, because every switch burdens your working memory and requires you to start afresh. So just focus on one task at a time, and ignore any and all distractions. Don’t even worry about the length of your to-do list; it will all get done in due time.

With this in mind, you should be able to accomplish more and increase your productivity without even worrying about where to start.

## The right algorithms can help you predict the future.

Most of us would love to be able to see into the future, but what about the next best thing: predicting what will probably happen?

With the help of algorithms, predicting probable outcomes isn’t so far-fetched.

This kind of forecasting goes back to eighteenth-century England, when Reverend Thomas Bayes figured out a basic method for predicting the likelihood of future events, such as drawing a winning lottery ticket, given certain prior events.

Let’s try applying Bayes’s logic to today’s lottery scratch tickets. Imagine you bought three scratchers and want to use them to understand what proportion of the tickets in circulation offer some kind of win. Bayes’s insight was that you have to start by hypothesizing about the prevalence of winners among all the tickets in circulation, and using this as an assumption, calculate the probability of the results you actually see in your three tickets.

For example, if all three of your tickets are winners, you could reasonably assume that all tickets in circulation offer a win. After all, if all tickets are winners, then you should witness three out of three tickets winning 100 percent of the time. But if only half the tickets were winners, then your threefold luck would have only had a 12.5-percent chance of befalling you. So it’s far likelier that all the tickets are winners.

Of course, the more information you collect, the more precise your next hypothesis will be.

But, over the years, math has developed and given us more precise tools to make better predictions.

What significantly helps those predictions is to understand the **distribution pattern** of a phenomenon.

For instance, there’s the famous “bell curve,” modeled on a **normal distribution**, which applies to many phenomena. When predicting the average age of a random group of people, you can assume that few people are extremely young or extremely old; most fall somewhere in the middle of the bell. This way, if you’re going on a blind date, you can be reasonably sure you won’t be dining with a nonagenarian.

Other situations follow the **power-law-distribution**, which is quite different.

In these cases, we reach the median average by having most observations falling below it and only a few enormous ones falling above it. An excellent example of this is wealth distribution. Generally speaking, there are many poor people and only a select few that own the lion’s share of the world’s wealth.

## Algorithms help us to exchange messages and handle data overload.

Here’s a classic thought experiment: Two generals are preparing to launch a joint attack on a city located in a fortified valley. The only problem is that each general is on a hill with the valley separating them, and before they can attack they need to agree on the exact time. However, the only way to get a message across is to send someone through the valley, where their messengers are likely to be captured. So how can they determine a time and know that the other has agreed to it?

This kind of problem is something computer scientists pondered in order to come up with algorithms to help ensure messages get to their destination safely.

The first method they devised is called **retransmitted till breakdown**. The idea would be to send in messenger after messenger, hoping that one will eventually make it through without being captured.

This is essentially what we do when we keep texting or calling a friend until they finally reply.

But of course, these days we mostly face other problems than intercepted messengers. Let’s say that every time you’re going to check your email you’re getting an error saying the server is overloaded.

In this case, the **Exponential Backoff** method can help. Instead of frantically hitting refresh, wait a couple minutes for the traffic to ease up. And if you’re still getting the error after that, double the waiting time to four minutes before trying again, and keep doubling until it gets through.

Ideally, everyone trying to use the server would follow this method, as it would help ensure a quick resolution.

But the best solution would be to prevent the overload problem in the first place, a method called **Additive Increase, Multiplicative Decrease** (AIMD).

This algorithm helps you determine the maximum amount of data a network can handle. It starts by sending just one package of data; then it sends double the amount each subsequent time until it reaches the point of overload.

Then it tries to pinpoint the limit by sending the highest amount before the failure occurred and increasing the subsequent packages by a tiny amount until the limit is reached.

## There are algorithms to help figure out what people will do and guide them when making decisions.

Have you ever heard of the **prisoner’s dilemma**? Imagine you and a partner have successfully robbed a bank. Later, you’re both brought in for questioning by the police and placed in separate rooms. You know they don’t have sufficient evidence to convict either of you for the robbery, so if you keep your mouth shut, all they can do is give you a one-year sentence for a lesser charge. After that, you will get out and can enjoy your loot.

But here’s the twist: the cops offer both you and your partner a deal: If you testify against your partner and he stays silent, you’ll go free and he’ll go to jail for ten years. However, if you both turn on each other, you’ll each get a five-year sentence. What do you do?

This is a classic** s**trategic question that represents **game theory**, which explores how rational people would respond to such a situation.

In the case of the prisoners, they would almost certainly turn on one another, in which case they’d each get a sentence of five years.

In this scenario there is a clear **maximum reward** – incriminate the other person, face no jail time and have a chance of keeping all the money. Even if your partner also talks, a five-year sentence is still better than the ten years you would get if you stay silent.

But, in the end, since each person would end up testifying against the other one, it’s the cops who win.

Another branch of game theory is the more straightforward **mechanism design**. Rather than setting options in the hopes of getting a certain reaction, it forces people to behave in a desirable way.

For example, many employers face the problem of employees not using their vacation time. And employers know that well-rested employees perform much better than overworked ones. The company Evernote went so far as to offer its staff a thousand-dollar bonus for taking time off, but even this didn’t work.

When you apply mechanism design to this problem, you don’t need to figure out ways of **convincing** your employees. All you need to do is ask yourself how to **make **them take their vacation.

And the answer is simple: Make vacations mandatory!

As you can see, algorithms have applications in many fields. Finally, in the last blink, let’s discuss their limitations.

## It’s important to know that algorithms have their limits.

When you’re trying to model something complicated, complex models are generally better than simple ones.

For example, if you’re developing a model to explain the cause of obesity, you’ll want a complex one that takes many factors into account, from a poor diet to genetics to lack of exercise. A simple model might focus solely on diet, which would be insufficient.

However, problems also arise when models grow too complex. This is a risk when considering real-world problems, where there’s always going to be uncertainty and errors in the data. Most likely, you’d start with a sample data set and would try to build an algorithm that makes predictions based on it. The temptation is to add variables to the algorithm until it explains everything in data perfectly, including the errors. This is known as **overfitting,** and it creates problems when you try to apply the same algorithm to different data. Basically, the model has been so rigorously adapted to the sample data that it has lost all flexibility and will not work well with any other data.

For example, when considering obesity, in your sample data you might notice that certain areas of the country have more obesity than others. But this could well be a coincidence, and if you tweak your model to emphasize the importance of a person’s location, it will worsen the predictive power of the model when you apply it to new data where location is inconsequential.

When you realize that perfect algorithms don’t exist, you can relax your standards a bit and go for good enough instead of perfect.

Consider the **travelling-salesman-problem**, which asks: How can you find the single best route between multiple points without having to go anywhere twice. If you expand this problem to a whole state or country, it gets unspeakably complex.

In a situation like this, the most efficient solution is to relax your standards. Let your salesman visit different locations at least twice. You’ll end up close to a good solution in a reasonable time, even if it might not be a perfect one.

As you’ve learned from these blinks, if you understand their limits and possibilities, algorithms can be applied in many areas of life.

## Final summary

The key message in this book:

**Algorithms are not incomprehensible things that only exist to help mathematicians and computers. In fact, we use them every day, even if we’re unaware of it. Algorithms contain a lot of problem-solving wisdom that can help you make good decisions, predict probable outcomes and become a more productive individual. **

Actionable advice:

**Do the simple stuff first.**

The next time your to-do list gets too long and you want to check off as many things as possible, go for the **Shortest Processing Time algorithm**: List your tasks in order of what can be done the fastest. This enables you to get lots of things done in a very short period of time.

**Got feedback?**

We’d sure love to hear what you think about our content! Just drop an email to remember@blinkist.com with the title of this book as the subject line and share your thoughts!

**Suggested** **further** **reading: ******How Not to Be Wrong ******by Jordan Ellenberg**

**How Not to Be Wrong** gives us an intimate glimpse into how mathematicians think and how we can benefit from their way of thinking. It also explains how easily we can be mistaken when we apply mathematical tools incorrectly, and gives advice on how we can instead find correct solutions.
