# Mindware
*by Richard E. Nisbett*

Source: [https://www.blinkist.com/books/mindware-en](https://www.blinkist.com/books/mindware-en)

![Mindware](https://images.blinkist.com/images/books/578a264ccc52f4000350f61d/1_1/470.jpg)

 (2015) is a guide to reason. These blinks explain why we make irrational assumptions while presenting the cognitive tools that statisticians, logicians and philosophers use to approach everyday problems with objectivity.


# What’s in it for me? Upgrade your reasoning skills.

Did you ever watch a friend do something incredibly stupid? Did it make you wonder, “How can such a smart person be such a fool?” Actually, we all act foolishly. Often, because we’re prone to making some very common reasoning mistakes.

These blinks lay out tools and methods, also known as “mindware,” that will help you think more logically and avoid such simple mistakes in the future. In these blinks, you’ll also learn how to best synthesize the information you get from study results, other people and the news in order to see the most objective picture possible.

By reading these blinks, you’ll also find out

- about a fear that’s making you miss out on superb deals;
- what ice cream has (or doesn’t have) to do with polio; and
- what’s so great about your own coffee mug.

# Correlation is not causation.

Have you ever heard that countries with a higher average IQ also enjoy higher average wealth? It’s true, but does that mean that being a smarter country makes you a richer one?

Actually, it’s easy to falsely assume that one thing causes another just because those two things occur at the same time, especially if it confirms something we already believe. But before we get ahead of ourselves, let’s define some basic statistical terms. For instance, **correlation**: if A and B occur simultaneously, then A positively **correlates** to B. But if A only occurs without B and B only without A, then the relationship is a **negative correlation**.

This is important because we tend to assume that A caused B, or vice versa, simply because they are correlated. For example, take the following scientifically proven correlation: on average, people who go to church are less likely to suffer premature death than those who don’t.

Given this information, if you believe in God, you might assume that believing in God increases a person’s lifespan. And there you have it: you’ve transformed a correlation into a causation. However, just because both events correlate to each other doesn’t mean that one **causes** the other.

In fact, assuming causation between events that are simply correlated can lead to major errors. For example, during the summers throughout the 1950s, there was a clear correlation between cases of polio and ice cream consumption; lots of people were eating ice cream and lots of people were contracting polio. But would banning ice cream have helped combat the polio epidemic? Definitely not.

That’s because ice cream obviously doesn’t cause polio. However, polio germs **are** transmitted by swimming in pool water and, just like ice cream, swimming pools are popular during the summertime.

Now that you know correlation isn't the same as causation, let's take another look at our first example:

Instead of assuming that intelligent citizens are what make countries wealthy, it'd be wiser to look at it from another angle: wealthy countries usually have superior health-care and education systems, and that produces people with higher IQs.

# 

“Want to make your employees more creative? Expose them to the Apple logo. And avoid exposing them to the IBM logo.”

# We favor evidence that matches our assumptions.

Everyone wants to think of themselves as an objective, rational person, not as someone who’s easily misled. But the truth is that we rely heavily on mental shortcuts that distort our judgment.

In fact, certain objects or traits can predispose us to seeing a relationship between things even if none exists. We do this because, we see some things and characteristics as representative of others. For instance, genitals represent sexuality and weapons signify aggression.

So, when a person sees someone bearing a loaded signifier they immediately jump to conclusions. For instance, they might perceive someone carrying a gun as a potential aggressor, even if he’s simply a museum attendant hanging an exhibition.

This happens because of a mental shortcut known as the **representativeness heuristic**. Due to this mind trick, even clinical psychologists are misled by what they’re prepared to see.

For example, in one experiment, psychologists were presented with a series of fabricated patient cards. Each one detailed the symptoms of the “patients”, as well as their responses to an inkblot test.

The cards stated that some patients saw genitals in the blots of ink, a fact that would lead most people to assume that these people had sexual problems. And that’s exactly what the psychologists assumed. Even though the experimenters had rigged the cards so that “patients” who saw genitals were (seemingly) less likely to report sexual adjustment problems, the majority of psychologists reported that this group of patients experienced a greater instance of such issues.

But you can also be predisposed to not perceive a relationship between entities. For instance, even when the psychologists were told that, contrary to their expectations, a negative correlation exists between seeing genitals during inkblot tests and sexual adjustment problems, they insisted that their clinical experience pointed to a positive one.

In reality, there’s no relationship whatsoever between the two, and their clinical experience likely reflects that. But the representativeness heuristic causes them to primarily remember the cases that meet their expectations.

# Humans fear risk more than they relish gain and tend to overvalue what they own.

Imagine someone approached you with a wager. They’d flip a coin: tails you win $120, heads you lose $100. The deal is obviously great, but does that mean you would take it?

In all likelihood, you wouldn’t. People are much more interested in avoiding losses than in accruing gains. Economists call this loss aversion. Various studies show that people would prefer to completely avoid the possibility of loss than take a risk, even if the chance of winning is high. For most people, the pain of losing is twice as acute as the pleasure of winning.

For example, in one study, the majority of participants declined a good deal like the one described above. They wouldn’t enter the bet unless they stood to win at least $200, twice the amount they risked losing – a fact that caused them to miss out on favorable odds.

But loss aversion isn’t the only bias that causes irrational behavior; thanks to the **endowment effect,** people tend to place greater value on objects they possess.

For instance, any rational person knows that a $5 coffee mug is worth just that, whether they own it or not. But a popular experiment has shown that people’s perceptions don’t align with this fact:

In the experiment, half of a class was given nice coffee mugs bearing their university’s logo. The other half got nothing. Then, the students without mugs were asked how much they would pay to own one and the students with mugs were asked how much money they’d be willing to sell theirs for.

The results were illuminating. On average, the asking price of the mug owners was twice as high as the amount the other students were willing to give. This discrepancy clearly indicates that the mere fact of owning an object changes the way its value is perceived.

So, our reasoning is flawed. How do we change that?

# Conduct your own research and don’t believe everything the media says.

In these times of media overload, it can be difficult to know who to trust. For instance, say you have a baby, and then you hear an expert on TV say that small children should be kept away from germs as much as possible. Is this sound advice?

Well, luckily there’s an easy way to find out and it doesn’t require you to experiment on your own baby:

Begin by collecting studies that are relevant to your question. You can do this by searching for studies that aim to answer more or less the same query, but are aimed at different conditions and groups. This method will prevent you from drawing conclusions from a single correlation.

While learning about the effects germs have on babies, you might, for example, find studies that draw connections between germ exposure and allergies. You might then encounter others saying that East Germans are less likely to have allergies than West Germans, that Russians are less likely to experience allergies than Finns and that farmers have fewer allergies than city dwellers.

All of these studies are based on one question: Which of the two groups is more likely to have allergies?

But after you gather this information you’ll need to interpret it while asking yourself how each study applies to your question. For example, you could ask **why** each study produced the outcome it did and how the results from all the studies relate to one another.

So, you can assume that, at least recently, East Germany and Russia were less hygienic than West Germany and Finland. You can also assume that people raised on farms are exposed to more diverse bacteria than those raised in cities. Since people on farms were less affected by allergies than others, we can assume that people living in places with a large variety of germs are less prone to autoimmune diseases and, therefore, that keeping your kids isolated from such germs could actually be **bad** for their health.

# Applying the laws of logic can protect you from subjective responses.

Do you ever find yourself listening to the illogical ramblings of a politician and wondering, “What’s this even supposed to prove?” Well, Aristotle likely had the same thought when listening to the weak arguments thrown back and forth in the Athenian assembly. As a result, the philosopher came up with principles of reasoning that enable anyone to analyze the validity of an argument.

These principles are the building blocks of **formal logic**, an approach that’s just as useful now as it was back in the days of Ancient Greece.

Formal logic works by representing constructs like this: if premise 1 and premise 2 are true, then the conclusion should also be true. For instance, take the spam email messages that people perpetually receive with subjects like, “Get $6000 with this easy trick!” To know if the conclusion is true we simply need to assess the premises.

In this case, the first premise is that the sender knows of a trick that will enable anyone to get $6,000 with a minimum of effort. The second is that, instead of using this trick to repeatedly make $6,000, the sender spends his time emailing strangers to tell them about it. How plausible is it that both are true?

So, logic works by taking away the real-world influences of prior beliefs to make reasoning more objective. This way, you’ll be less swayed by the influence of prejudice and bias because you’ll just be considering the facts.

For example, say you’re choosing someone for an engineering job. To avoid prejudice against women, you could hide the gender of the candidates and then list the characteristics that make an applicant promising, like “realized successful projects in prior positions.” Then, if someone meets all your criteria, you’ll know they’re a potential fit, regardless of their gender.

# Final summary

The key message in this book:

**Everyone wants to be rational, but there are common and invisible habits that prevent us from thinking objectively. By noticing such traps and defending ourselves against them, we can avoid irrationality and make logical choices. **

Actionable Advice:

**Use Occam's Razor to find the simplest solution. **

Sometimes we’re faced with situations in which more than one theory is correct. How do you know which one to trust? Go with an approach named after Franciscan friar William of Ockham called Occam’s Razor. It goes like this: always pick the simplest theory. Why? Well, easier theories are easier to test and model mathematically. Plus, complicated theories rarely explain evidence as well as simple ones do.

**Got feedback?**

We’d sure love to hear what you think about our content! Just drop an email to remember@blinkist.com with the title of this book as the subject line and share your thoughts!

**Suggested further reading: ******Drunk Tank Pink ******by Adam Alter**

**Drunk Tank Pink** probes the hidden psychological and social influences that shape the way we see, think, feel, and act in the world.
